<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
    <title>Scholarly HTML</title>
    <link rel="stylesheet" href="css/scholarly.min.css">
  </head>
  <body prefix="schema: http://schema.org">
    <header>
      <div class="banner">
        <img src="watr.png" width="80" height="80" alt="WATR logo">
        <div class="status">WATR</div>
      </div>
      <h1>Web Data Commons Analyzer</h1>
    </header>

    <div role="contentinfo">
      <ol role="directory">
        <li><a href="#abstract"><span>1. </span>Abstract</a></li>
        <li><a href="#introduction"><span>2. </span>Introduction</a></li>
        <li><a href="#architecture"><span>3. </span>System Architecture</a>
          <ol role="directory">
            <li><a href="#design"><span>3.1 </span> Services Design </a></li>
            <li><a href="#technologies"><span>3.2 </span> Technologies Used</a></li>
            <li><a href="#data-flow"><span>3.3 </span> Data Flow </a></li>
          </ol>
        </li>
        <li><a href="#functionalities"><span>4. </span> Core Functionalities</a>
          <ol role="directory">
            <li><a href="#dataset"><span>4.1 </span> Dataset Ingestion &amp; Preprocessing </a></li>
            <li><a href="#visualization"><span>4.2 </span> Visualization </a></li>
            <li><a href="#matching"><span>4.3 </span>  Vocabulary Matching </a></li>
            <li><a href="#statistics"><span>4.4 </span>  Data Analytics &amp; Statistics </a></li>
          </ol>
        </li>
        <li><a href="#implementation"><span>5. </span> Implementation &amp; Deployment</a>
          <ol role="directory">
            <li><a href="#backend"><span>5.1 </span> Backend: Spring Boot &amp; Jena Integration </a></li>
            <li><a href="#Frontend"><span>5.2 </span>  Frontend: Thymeleaf &amp; HTMX Enhancements</a></li>
            <li><a href="#api-query"><span>5.3 </span>  API Layer &amp; Internal Query Processing</a></li>
            <li><a href="#deployment"><span>5.4 </span>  Deployment Strategy</a></li>
          </ol>
        </li>
        <li><a href="#testing"><span>6. </span> Validation &amp; Testing</a>
          <ol role="directory">
            <li><a href="#performance"><span>6.1 </span>  Performance Evaluation </a></li>
            <li><a href="#use-cases"><span>6.2 </span>  Usability &amp; Use Cases</a></li>
          </ol>
        </li>
        <li><a href="#conclusion"><span>7. </span> Conclusion &amp; Future Work</a>
          <ol role="directory">
            <li><a href="#contributions"><span>7.1 </span> Summary of Contributions </a></li>
            <li><a href="#enhancements"><span>7.2 </span>  Potential Enhancements</a></li>
          </ol>
        </li>
        <li><a href="#references"><span>8. </span>References</a></li>
      </ol>
      <dl>
        <dt>Authors</dt>
        <dd>
          <span about="#author1" typeof="schema:Person">
  <span property="schema:name">Radulescu Richard-Andrei</span>
</span>
          &amp;
          <span about="#author2" typeof="schema:Person">
  <span property="schema:name">Buimestru Alexandru</span>
</span>


        </dd>
        <dt>Project Repository</dt>
        <dd>
          <a href="https://github.com/RadulescuRichardAndrei/Watr">WATR Github</a>
        </dd>
        <dt>License</dt>
        <dd>
          <a href="https://opensource.org/license/cmu-license">MIT-CMU</a>
        </dd>
      </dl>
    </div>
    <section typeof="sa:Abstract" id="abstract" role="doc-abstract">
      <h2><span>1. </span>Abstract</h2>
      <p>
        This paper presents the design and implementation of a service-oriented web application for processing and analyzing
        structured metadata in RDFa and HTML5 microdata formats. The system processes user-provided datasets and offers core
        functionalities such as visualization, classification, comparison, and matching/alignment.
        The system integrates internal query services (SPARQL) that process RDF data efficiently,
        providing structured results in HTML and JSON-LD formats. Additionally, statistical
        insights are derived and modeled using the RDF Data Cube vocabulary,
        offering valuable analytical perspectives on the extracted metadata.
      </p>
    </section>
    <section id="introduction" role="doc-introduction">
      <!-- review? -->
      <h2><span>2. </span>Introduction</h2>
      <p>
        The rapid growth of structured data on the web has transformed how information is shared, discovered, and analyzed.
        Formats like RDFa and HTML5 microdata, which enable web pages to embed machine-readable metadata,
        are pivotal for the semantic web and improving data interoperability.
        We provide a service-based web application designed to streamline the processing and analysis
        of RDF data.  By focusing on a modular architecture, the system offers a minimal
        set of core functionalities that can be easily expanded and integrated.
        These functionalities include data visualization, classification, comparison and vocabulary matching.
        The data is returned in user-friendly formats such as HTML and JSON-LD, making it accessible
        for a wide range of users, from developers to researchers.
        Additionally, the application generates statistical insights modeled using the RDF Data Cube vocabulary,
        which helps in deriving meaningful analytical perspectives from the metadata.
      </p>

    </section>

    <section id="architecture">
      <h2><span>3. </span>System Architecture</h2>
      <p>
        The system is built on a Spring Boot application (which has the same architecture of Spring MVC) that follows a modular and service-oriented architecture,
        enabling efficient management of datasets and their processing.
      </p>

      <section id="design">
        <h3><a><span>3.1 </span> Services Design </a></h3>
        <p>
          The application is structured around multiple
          controllers and services that handle different tasks. The Dataset Controller is responsible for
          managing the lifecycle of datasets, allowing users to upload, save, and delete their data. Once uploaded,
          the datasets are stored and loaded into an embedded Fuseki Jena server, providing a robust platform for querying and processing RDF data.
          The Visualization Controller and Statistics Controller are responsible for generating dynamic visual representations and statistical insights, respectively.
        </p>
      </section>
      <section id="technologies">
        <h3> <a><span>3.2 </span> Technologies Used </a></h3>
        <h4>View Layer with Thymeleaf and HTMX and Bootstrap for Responsive Design</h4>
        <p>
          The front-end of the application is built using Thymeleaf in combination with HTMX,
          creating a dynamic and responsive user interface. Thymeleaf serves as the primary templating engine,
          enabling the construction of robust HTML pages that are easily maintainable and reusable. HTMX enhances these pages by allowing seamless,
          asynchronous updates without requiring a full-page reload.
          Bootstrap is integrated to ensure that the application maintains a clean, responsive layout, allowing these visual components to adapt seamlessly across devices.
        </p>
        <h4>Model Layer with Embedded Jena Fuseki Server</h4>
        <p>
          On the backend, an embedded Jena Fuseki server is utilized to construct and manage the data model.
          This powerful RDF data store is integrated into the application via dedicated service components,
          which handle the ingestion, querying, and manipulation of RDF data. The services load user-uploaded
          datasets into the Fuseki server, where the data is structured as RDF graphs, enabling querying using SPARQL.
          By leveraging the capabilities of Jena Fuseki, the system ensures efficient data
          processing and retrieval, which in turn supports dynamic content generation and detailed analytics presented to users.
        </p>
        <h4>Vis.js Networks for Triplet Visualization</h4>
        <p>Vis.js provides a dynamic and interactive network visualization component that is ideal for displaying RDF triplets.
          It enables users to explore relationships within the data by visually representing nodes and edges,
          making it easier to understand complex connections. The interactive features, such as zooming, panning,
          and node selection, enhance the user experience by allowing real-time exploration and manipulation of the network.</p>
        <h4>Chart.js for Statistical Graphs</h4>
        <p>
          Chart.js is utilized to present statistical data in engaging, easy-to-understand graphs,
          giving users clear insights through various chart types like line, bar, and pie charts.
          Its simplicity and versatility make it an excellent tool for visual data analysis.
        </p>
      </section>
      <section id="data-flow">
        <h3> <a><span>3.3 </span> Data Flow </a></h3>  <!-- ALEX  -->
        <p>
          The system architecture follows the Model-View-Controller (MVC) pattern, separating concerns between data management, 
          business logic and user interface. The data flow begins when a user uploads a dataset in the allowed format. 
          The application processes this data and stores it in an Apache Jena Fuseki triple store. After this, user can execute 
          queries to extract insights about data, which are visualized using various front-end tools. Also, for the future, it is 
          possible to download the stored dataset files, or delete them from the triple store.
        </p>
        <h4>Data Flow Steps</h4>
        <p>
          <ul>
            <li>
              <b>Data Ingestion</b>: Users upload structured metadata files through the DatasetController. 
              The system verifies their format before ingestion.
            </li>
            <li>
              <b>Storage</b>: The validated datasets are stored in an embedded Apache Jena Fuseki server using.
            </li>
            <li>
              <b>Query Processing</b>: The application executes SPARQL queries on the stored data via the DatasetQueryService, 
              GenericQueryService and StatisticQueryService to extract relevant information.
            </li>
            <li>
              <b>Visualization</b>: DatasetVisualizeController handles graph-based visualization using Vis.js. 
              DatasetStatisticController generates statistical insights using Chart.js.
              HTML tables with RDFa metadata are rendered via Thymeleaf templates.
            </li>
            <li>
              <b>Export</b>: Processed data can be exported in JSON-LD format or as a PNG image for further use.
            </li>
          </ul>
        </p>
        <img src="images/MVCDiagram.png" alt="MVC Diagram" class="responsive-img">
      </section>

    </section>

    <section id="functionalities">
      <h2><span>4. </span> Core Functionalities</h2>  <!-- RICHARD -->

      <section id="dataset">
        <h3><a><span>4.1 </span> Dataset Ingestion & Preprocessing </a></h3>
        <p>
          The Dataset Ingestion & Preprocessing module of the web application provides a seamless interface for
          managing datasets compatible with the embedded Jena Fuseki server. Users can upload datasets through
          intuitive forms that support various semantic web formats, including .ttl, .rdf, .nt, .nq, .jsonld,
          .trig, .owl, .trdf, .rt, .rpb, .pbrdf, .rj, and .trix. The system allows for efficient dataset storage and deletion,
          ensuring flexibility in managing linked data resources. These uploaded datasets serve as the foundation for other
          core functionalities within the application, enabling robust querying, analysis, and knowledge graph management.
        </p>
      </section>
      <section id="visualization">
        <h3> <a><span>4.2 </span> Visualization </a></h3>
        <p>
          The Visualization component of the web application introduces a dynamic,
          table-based interface designed for seamless data representation. This interface
          presents datasets in a paginated table format, enabling users to easily navigate
          through large amounts of information without overwhelming the display.
          Although the current implementation does not include search or filtering functionalities,
          the design focuses on providing a clean and straightforward user experience, ensuring that users can browse data efficiently.


        </p>
        <p>
          In addition to its user-friendly appearance, the table is crafted to be machine-readable
          by incorporating RDFa attributes into its markup. This dual-format approach not only
          enhances accessibility for end-users but also supports automated data processing
          and integration with other semantic web tools. By adhering to RDFa standards, the
          visualization component ensures that both human readers and software agents can effectively
          interpret and utilize the presented data, thereby extending the application's overall interoperability and functionality.
        </p>
        <p>
          The second visualization approach employs the vis.js network library to provide a dynamic,
          graphical representation of data triplets, rendered as node–edge–node structures (subject, predicate, object).
          Users can interact with the graph through intuitive filters that control the display of each element
          type—allowing for the selective addition or removal of subjects, predicates, or objects.
          The graph comes equipped with interactive features such as zooming, panning, and dragging,
          making navigation and exploration seamless even as the complexity of the network increases.

        </p>
        <p>
          When users click on any element within the graph, a detailed information panel
          is presented, divided into three key sections. The first section outlines the core
          identifiers and terminological descriptors, offering essential context about the data's structure.
          The second section delves into relational properties, displaying connections such as equivalencies and subclass relationships,
          which are enriched by external data sourced from DBpedia and Wikidata.
          The third section provides statistical insights, including counts, appearance frequencies, and the in/out degrees of nodes,
          empowering users with both qualitative and quantitative perspectives on the dataset.
        </p>
        <p>
          This graphical representation can be saved as an image and in json-ld format.
        </p>
      </section>
      <section id="matching">
        <h3> <a><span>4.3 </span> Vocabulary Matching </a></h3>
        <p>
          The Vocabulary Matching functionality is designed to identify and reconcile corresponding
          elements between two selected datasets. Initially, the system extracts all subjects, predicates,
          and objects—categorizing them based on RDF resource types (IRIs)—from the datasets provided via a form.
          Two distinct approaches are then combined to perform the matching. The first method involves a
          similarity measure, using the Levenshtein distance, based on comparing the local names extracted from each resource's identifier,
          applying a predetermined criterion to include the most similar pairs. In parallel,
          the system leverages external knowledge sources such as DBpedia and Wikidata to
          validate and detect equivalencies based on established semantic relationships.
          The matching results are organized into clearly segmented tables, categorizing
          findings by the type of matching: one for the string-based approach, one for
          DBpedia, and one for Wikidata, with each table further subdividing the data based on subjects, predicates, and objects.
        </p>
      </section>
      <section id="statistics">
        <h3> <a><span>4.4 </span> Data Analytics & Statistics </a></h3>
        <p>
          The Data Analytics & Statistics section offers users comprehensive insights into dataset
          distributions through an intuitive, form-based interface. Users can examine the top 10 most frequently occurring subjects,
          predicates, and objects within a dataset. Additionally,
          when a specific predicate is selected, the system displays a detailed distribution
          of its associated objects. The visualization adapts to the nature of the data: if the objects are
          numeric values, the data is depicted using a bar chart, whereas non-numeric data is presented in a pie chart.
          These dynamic charts are rendered using the Chart.js library, ensuring interactive and aesthetically
          pleasing graphical representations that support effective data exploration and analysis.
        </p>
      </section>
    </section>

    <section id="implementation"> <!-- RICHARD -->
      <h2><span>5. </span> Implementation & Deployment</h2>
      <section id="backend">
        <h3> <a><span>5.1 </span> Backend: Spring Boot & Jena Integration </a></h3>
        <p>
          The backend of the application is built using Spring Boot, with an embedded Apache Jena Fuseki server to handle
          RDF data storage and querying. The integration ensures that the application can manage
          linked data efficiently while enabling internal SPARQL querying within the application.
          The Fuseki server is configured to load datasets from a specified directory, making it accessible for data ingestion, retrieval, and analysis.
        </p>
        <p>
          To facilitate interaction with the RDF data, the application is structured into specialized
          service layers. One set of services focuses on managing dataset files—handling ingestion, storage,
          and removal—ensuring that data is correctly integrated into the Jena triple store. The second set
          of services is dedicated to querying the Fuseki server using SPARQL, further divided into
          a general-purpose service for retrieving RDF data and a statistics service that extracts analytical insights,
          such as entity distributions and relationships. Queries are constructed dynamically using parameterized queries
          and query builders, improving flexibility and security.
        </p>
        <p>
          These services interact with Spring Boot controllers, which process the retrieved data
          and construct the model used by the Thymeleaf template engine. The templates dynamically
          generate asynchronous content, ensuring that users receive up-to-date information without requiring
          full-page reloads. This architecture enables an efficient, responsive, and structured approach to
          managing and visualizing RDF datasets within the web application.
        </p>
      </section>
      <section id="Frontend">
        <h3> <a><span>5.2 </span> Frontend: Thymeleaf & HTMX Enhancements</a></h3>
        <p>
          The frontend leverages Thymeleaf as the templating engine, seamlessly integrating with HTMX to
          enhance dynamic content updates without requiring full-page reloads. HTMX allows for efficient
          server-driven UI updates by handling AJAX requests declaratively, making it a natural fit for
          Thymeleaf-based applications. The use of <code>hx-boost</code> further improves navigation by transforming
          traditional links into asynchronous requests, enabling a smooth and responsive user experience
          while keeping the complexity on the backend. This combination ensures a clean separation between
          logic and presentation while maintaining high performance and minimal JavaScript overhead.
        </p>
      </section>
      <section id="api-query">
        <h3> <a><span>5.3 </span> API Layer & Internal Query Processing</a></h3>
        <p>
          The application exposes a RESTful API that conforms to standard web architecture principles.
          The API is defined via an <a href="open-api.json" target="_blank">OpenAPI specification</a>, providing a clear and organized contract for
          client-server interaction. Endpoints are grouped by functionality (e.g., dataset management, visualization, statistics, and filtering)
          to promote modularity and maintainability.
        </p>
        <h4>Query 1: Count Predicates for a Given Object</h4>
        <p>
          The first query dynamically constructs a SPARQL query to count how many subjects are associated
          with each predicate that connects them to a specific <u>object</u>. In the query, the value of the variable
          <code>object</code> is inserted into the triple pattern. The query groups the results by <code> predicate</code>
          so that for each predicate found, the total number of related subjects is computed.
        </p>
        <p>The resulting query string is similar to:</p>
        <pre><code>SELECT ?predicate (COUNT(?subject) AS ?count)
WHERE {
  ?subject ?predicate <u>[object]</u> .
}
GROUP BY ?predicate
        </code>
        </pre>
        <p>
          Here, the variable <u>[object]</u> represents the dynamically inserted value. This query is useful for obtaining a statistical distribution of predicates based on a fixed object value.
        </p>

        <h4>Query 2: Retrieve Equivalent RDF Properties via a Federated Query</h4>
        <p>
          The second query is designed to find pairs of properties that are considered equivalent according to the <code>owl:equivalentProperty</code> relation. It uses a federated query (via the <code>SERVICE</code> keyword) to query an external SPARQL endpoint – for example, DBpedia – to retrieve this information.
        </p>
        <p>
          In this query, two sets of property values are injected into the query via the variables <code>firstString</code> and <code>secondString</code>. The query then checks for either direction of the equivalence relation (i.e. <code>?prop1 owl:equivalentProperty ?prop2</code> or vice versa) to ensure all possible equivalent pairs are captured. The <code>SELECT DISTINCT</code> ensures that duplicate pairs are not returned.
        </p>
        <p>The resulting query string looks like this:</p>
        <pre><code>PREFIX owl: &lt;http://www.w3.org/2002/07/owl#&gt;
SELECT DISTINCT ?prop1 ?prop2
WHERE {
  SERVICE &lt;<u>[dbpediaEndpoint]</u>&gt; {
    VALUES ?prop1 { <u>[firstString]</u> }
    VALUES ?prop2 { <u>[secondString]</u> }
    { ?prop1 owl:equivalentProperty ?prop2 }
    UNION
    { ?prop2 owl:equivalentProperty ?prop1 }
  }
}
</code></pre>
        <p>
          In the example above, <u>[dbpediaEndpoint]</u>, <u>[firstString]</u>, and <u>[secondString]</u> denote variables that hold the endpoint URL and the lists of property values, respectively. This federated query design allows the system to seamlessly integrate external semantic data to enhance internal processing and data enrichment.
        </p>


      </section>
      <section id="deployment">
        <h3> <a><span>5.4 </span> Deployment Strategy</a></h3>
        <p>
          Our deployment strategy leverages Maven to build an executable JAR file that contains
          all necessary dependencies. By configuring our <code>pom.xml</code> appropriately,
          we package the application into a “fat JAR” during the Maven build process. This JAR is
          fully self-contained and can be deployed on any machine that has a compatible Java Runtime Environment (JRE).
        </p>
        <p>
          Once built, the JAR can be easily deployed to a specific server, where it is executed as a
          standalone application. This approach not only simplifies the deployment process but also ensures
          that the application is platform-independent, making it straightforward to deploy in various environments.
          Additionally, the integration of Maven with our continuous integration pipeline allows for automated builds
          and testing, enhancing the reliability and maintainability of our deployment process.
        </p>
      </section>
    </section>

    <section id="testing">
      <h2><span>6. </span> Validation & Testing</h2>
      <section id="performance">
        <h3> <a><span>6.1 </span> Performance Evaluation </a></h3><!-- RICHARD -->

      </section>
      <section id="use-cases">
        <h3> <a><span>6.2 </span> Usability & Use Cases</a></h3><!-- ALEX -->
          <h4>Uploading a Dataset</h4>
          <p>
            Users can upload a dataset containing RDF metadata through the web interface. 
            The system validates the file format before storing it in the Apache Jena Fuseki triple store. 
            A confirmation message is displayed once the upload is successful.
          </p>
          <img src="images/uploadDataset.PNG" alt="uploadDataset" class="responsive-img">
          <h4>Visualizing RDF Data as Graphs</h4>
          <p>
            Users can explore the dataset structure using an interactive Vis.js-powered graph. 
            RDF triplets are rendered as subject-predicate-object relationships, with filtering options to refine the visualization. 
            Clicking on nodes displays detailed metadata and linked data sources (e.g., DBpedia, Wikidata).
          </p>
          <img src="images/graphView.PNG" alt="graphView" class="responsive-img">
          <h4>Exporting Processed Data</h4>
          <p>
            After analyzing the dataset, users can export the processed data in JSON-LD format or as a PNG image. 
            In particular, JSON-LD format ensures compatibility with other semantic web tools and facilitates integration 
            with external applications.
          </p>
          <img src="images/exportData.PNG" alt="exportData" class="responsive-img">
          <h4>Querying Predicate Details</h4>
          <p>
            Users can select a specific predicate to view its details, including associated subjects and objects. 
            Upon selection, a dynamically generated interactive graph provides the visual insights about predicate
            relationships, and additional details, relations and statistics are presented in dedicated sections. 
            This feature enhances data exploration by revealing semantic connections.
          </p>
          <img src="images/predicateDetails.PNG" alt="predicateDetails" class="responsive-img">
          <h4>Statistical Analysis of Predicate-Object Distribution</h4>
          <p>
            The system generates statistical insights about predicates, displaying them using dynamic pie charts. 
            When a predicate is selected, the associated objects are analyzed, and their distribution is visualized.
          </p>
          <img src="images/pieChart.PNG" alt="uploadDataset" class="responsive-img">
      </section>
    </section>

    <section id="conclusion"><!-- RICHARD -->
      <h2> <span>7. </span>Conclusion & Future Work</h2>
      <section id="contributions">
        <h3> <a><span>7.1 </span> Summary of Contributions </a></h3>
        <ul>
          <li about="#author1" typeof="schema:Person">
            <strong property="schema:name">Radulescu Richard-Andrei</strong>
            <ul>
              <li>Visualization</li>
              <li>Dataset Management (in collaboration)</li>
              <li>Statistics (in collaboration)</li>
              <li>Documentation &amp; Source Control (in collaboration)</li>
              <li>User Interface (in collaboration)</li>
              <li>Deployment</li>
            </ul>
          </li>
          <li about="#author2" typeof="schema:Person">
            <strong property="schema:name">Buimestru Alexandru</strong>
            <ul>
              <li>Dataset Management (in collaboration)</li>
              <li>Statistics (in collaboration)</li>
              <li>Documentation &amp; Source Control (in collaboration)</li>
              <li>User Interface (in collaboration)</li>
            </ul>
          </li>
        </ul>

      </section>
      <section id="enhancements">
      <h3> <a><span>7.2 </span> Potential Enhancements </a></h3>
        <p>
          Future work on the project may focus on the following enhancements:
        </p>
        <ul>
          <li>Adding more user-useful statistics to provide deeper insights.</li>
          <li>Enabling better exploration of datasets through improved table-based interfaces.</li>
          <li>Improving the API for enhanced performance and flexibility.</li>
          <li>Developing user-specific workspaces and a share system to facilitate collaboration.</li>
        </ul>
      </section>

    </section>
    <section id="references"> <!-- RICHARD -->
      <h2><span>8. </span>References</h2>
      <ul>
        <li itemprop="citation" itemscope itemtype="http://schema.org/CreativeWork">
          <span itemprop="name">Start Bootstrap SB Admin Template</span>.
          <a href="https://startbootstrap.com/template/sb-admin" target="_blank" itemprop="url">
            https://startbootstrap.com/template/sb-admin
          </a>
        </li>
        <li itemprop="citation" itemscope itemtype="http://schema.org/CreativeWork">
          <span itemprop="name">HTMX Library</span>.
          <a href="https://htmx.org/" target="_blank" itemprop="url">
            https://htmx.org/
          </a>
        </li>
        <li itemprop="citation" itemscope itemtype="http://schema.org/CreativeWork">
          <span itemprop="name">Bootstrap Library</span>.
          <a href="https://getbootstrap.com/" target="_blank" itemprop="url">
            https://getbootstrap.com/
          </a>
        </li>
        <li itemprop="citation" itemscope itemtype="http://schema.org/CreativeWork">
          <span itemprop="name">Thymeleaf</span>.
          <a href="https://www.thymeleaf.org/" target="_blank" itemprop="url">
            https://www.thymeleaf.org/
          </a>
        </li>
        <li itemprop="citation" itemscope itemtype="http://schema.org/CreativeWork">
          <span itemprop="name">Spring Boot</span>.
          <a href="https://spring.io/projects/spring-boot" target="_blank" itemprop="url">
            https://spring.io/projects/spring-boot
          </a>
        </li>
        <li itemprop="citation" itemscope itemtype="http://schema.org/CreativeWork">
          <span itemprop="name">vis.js</span>.
          <a href="https://visjs.org/" target="_blank" itemprop="url">
            https://visjs.org/
          </a>
        </li>
        <li itemprop="citation" itemscope itemtype="http://schema.org/CreativeWork">
          <span itemprop="name">Chart.js</span>.
          <a href="https://www.chartjs.org/" target="_blank" itemprop="url">
            https://www.chartjs.org/
          </a>
        </li>
        <li itemprop="citation" itemscope itemtype="http://schema.org/CreativeWork">
          <span itemprop="name">Fuseki Jena</span>.
          <a href="https://jena.apache.org/documentation/fuseki2/" target="_blank" itemprop="url">
            https://jena.apache.org/documentation/fuseki2/
          </a>
        </li>
        <li itemprop="citation" itemscope itemtype="http://schema.org/ScholarlyArticle">
          <span itemprop="name">Empirical Best Practices On Using Product-Specific Schema.org</span>.
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
          <span itemprop="name">Mayank Kejriwal</span>
          </span>,
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span itemprop="name">Ravi Kiran Selvam</span>
          </span>,
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span itemprop="name">Chien-Chun Ni</span>
          </span>,
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span itemprop="name">Nicolas Torzec</span>
          </span>.
          <span>1 University of Southern California</span>.
          <a href="https://cdn.aaai.org/ojs/17816/17816-13-21310-1-2-20210518.pdf" target="_blank" itemprop="url">
            https://cdn.aaai.org/ojs/17816/17816-13-21310-1-2-20210518.pdf
          </a>
        </li>
      </ul>
    </section>
  </body>
</html>
